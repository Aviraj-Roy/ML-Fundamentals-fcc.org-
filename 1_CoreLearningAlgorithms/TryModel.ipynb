{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
      "0          6.4         2.8          5.6         2.2        2\n",
      "1          5.0         2.3          3.3         1.0        1\n",
      "2          4.9         2.5          4.5         1.7        2\n",
      "3          4.9         3.1          1.5         0.1        0\n",
      "4          5.7         3.8          1.7         0.3        0\n",
      "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "0          6.4         2.8          5.6         2.2\n",
      "1          5.0         2.3          3.3         1.0\n",
      "2          4.9         2.5          4.5         1.7\n",
      "3          4.9         3.1          1.5         0.1\n",
      "4          5.7         3.8          1.7         0.3\n",
      "(120, 4)\n"
     ]
    }
   ],
   "source": [
    "#tensorflow_version 2.x \n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf     \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "#Constants defined to help us\n",
    "\n",
    "train_path = tf.keras.utils.get_file(\"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "#We use \"keras\"(a module inside tensorflow) to grab our datasets and read them into a pandas dataframe\n",
    "\n",
    "print(train.head())\n",
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "print(train.head())\n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Function\n",
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    #Convert inputs to a Dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    \n",
    "    #shuffle and repeat if you are in training mode\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "        \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\royav\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6027 - loss: 1.3651  \n",
      "Epoch 2/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4596 - loss: 1.1352 \n",
      "Epoch 3/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3910 - loss: 0.9913\n",
      "Epoch 4/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7092 - loss: 0.9088 \n",
      "Epoch 5/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.7279 - loss: 0.8490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x122d94faf60>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation='relu', input_shape=(4,)),  # Input layer\n",
    "    tf.keras.layers.Dense(10, activation='relu'),  # Hidden layer 1\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train, train_y, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.5333 - loss: 0.9581\n",
      "\n",
      "Test Set Accuracy: 0.533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "#eval_result = model.evaluate(input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "eval_result = model.evaluate(test, test_y)\n",
    "print('\\nTest Set Accuracy: {accuracy:0.3f}\\n'.format(accuracy=eval_result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type numeric values as prompted.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Prediction is \"Virginica\" (45.9%)\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "predict={}\n",
    "\n",
    "print(\"Please type numeric values as prompted.\")\n",
    "for feature in features:\n",
    "    valid = False\n",
    "    while not valid:\n",
    "        val = input(feature+\": \")\n",
    "        if val.replace('.', '', 1).isdigit():\n",
    "            valid = True\n",
    "        else:\n",
    "            print(\"Please enter a valid numeric value.\")\n",
    "        \n",
    "    predict[feature] = [float(val)]\n",
    "\n",
    "#predictions = model.predict(input_fn=lambda: input_fn(predict, labels=None, training=False))\n",
    "predictions = model.predict(pd.DataFrame(predict))\n",
    "class_id = tf.argmax(predictions, axis=1).numpy()[0]\n",
    "probability = predictions[0][class_id]\n",
    "\n",
    "print('Prediction is \"{}\" ({:.1f}%)'.format(SPECIES[class_id], 100*probability))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
